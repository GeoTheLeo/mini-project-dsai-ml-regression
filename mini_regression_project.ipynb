{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea16843d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 21596 rows, 21 columns\n",
      "\n",
      "Columns in dataset:\n",
      "['7129300520', '10/13/14', '3', '1', '1180', '5650', '1.1', '0', '0.1', '3.1', '7', '1180.1', '0.2', '1955', '0.3', '98178', '47.5112', '-122.257', '1340', '5650.1', '221900']\n",
      "\n",
      "============================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "============================================================\n",
      "Empty DataFrame\n",
      "Columns: [Missing Count, Missing %]\n",
      "Index: []\n",
      "✓ No missing values found!\n",
      "\n",
      "============================================================\n",
      "BASIC STATISTICAL SUMMARY\n",
      "============================================================\n",
      "Numerical columns (20): ['7129300520', '3', '1', '1180', '5650', '1.1', '0', '0.1', '3.1', '7', '1180.1', '0.2', '1955', '0.3', '98178', '47.5112', '-122.257', '1340', '5650.1', '221900']\n",
      "Categorical columns (1): ['10/13/14']\n",
      "\n",
      "Basic statistics for key variables:\n",
      "         7129300520         3         1      1180        5650       1.1  \\\n",
      "count  2.159600e+04  21596.00  21596.00  21596.00    21596.00  21596.00   \n",
      "mean   4.580356e+09      3.37      2.12   2080.36    15099.85      1.49   \n",
      "std    2.876750e+09      0.93      0.77    918.11    41413.55      0.54   \n",
      "min    1.000102e+06      1.00      0.50    370.00      520.00      1.00   \n",
      "25%    2.123049e+09      3.00      1.75   1430.00     5040.00      1.00   \n",
      "50%    3.904930e+09      3.00      2.25   1910.00     7619.00      1.50   \n",
      "75%    7.308950e+09      4.00      2.50   2550.00    10685.50      2.00   \n",
      "max    9.900000e+09     33.00      8.00  13540.00  1651359.00      3.50   \n",
      "\n",
      "              0       0.1       3.1         7  \n",
      "count  21596.00  21596.00  21596.00  21596.00  \n",
      "mean       0.01      0.23      3.41      7.66  \n",
      "std        0.09      0.77      0.65      1.17  \n",
      "min        0.00      0.00      1.00      3.00  \n",
      "25%        0.00      0.00      3.00      7.00  \n",
      "50%        0.00      0.00      3.00      7.00  \n",
      "75%        0.00      0.00      4.00      8.00  \n",
      "max        1.00      4.00      5.00     13.00  \n",
      "\n",
      "============================================================\n",
      "TARGET VARIABLE ANALYSIS (PRICE)\n",
      "============================================================\n",
      "Warning: Could not find price column in dataset\n",
      "Available columns: ['7129300520', '10/13/14', '3', '1', '1180', '5650', '1.1', '0', '0.1', '3.1', '7', '1180.1', '0.2', '1955', '0.3', '98178', '47.5112', '-122.257', '1340', '5650.1', '221900']\n",
      "\n",
      "============================================================\n",
      "CORRELATION ANALYSIS\n",
      "============================================================\n",
      "Not enough numerical columns for correlation analysis\n",
      "\n",
      "============================================================\n",
      "HIGH-VALUE PROPERTIES ANALYSIS (≥ $650K)\n",
      "============================================================\n",
      "Cannot analyze high-value properties: Price column not found\n",
      "\n",
      "============================================================\n",
      "MODELING PHASE\n",
      "============================================================\n",
      "Skipping modeling phase - insufficient data or price column not found\n",
      "Price column found: None\n",
      "Numerical columns: 20\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =========== PART 1: COMPREHENSIVE EDA ===========\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load and basic info - FIXED WITH YOUR FILE PATH\n",
    "df = pd.read_csv('data/regression_data.csv')\n",
    "print(f\"Dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# Check what columns we have\n",
    "print(f\"\\nColumns in dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# 2. Check missing values\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percentage = (missing_counts / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_counts,\n",
    "    'Missing %': missing_percentage\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "if missing_counts.sum() == 0:\n",
    "    print(\"✓ No missing values found!\")\n",
    "\n",
    "# 3. Statistical summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASIC STATISTICAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "# Basic stats for key numerical variables (including price if it exists)\n",
    "if 'price' in df.columns:\n",
    "    key_vars = ['price', 'sqft_living', 'grade', 'bathrooms', 'bedrooms', \n",
    "                'sqft_lot', 'condition', 'waterfront', 'sqft_above', \n",
    "                'sqft_living15', 'sqft_lot15']\n",
    "else:\n",
    "    # Find similar column names\n",
    "    price_col = None\n",
    "    for col in df.columns:\n",
    "        if 'price' in col.lower():\n",
    "            price_col = col\n",
    "            break\n",
    "    \n",
    "    if price_col:\n",
    "        key_vars = [price_col, 'sqft_living', 'grade', 'bathrooms', 'bedrooms']\n",
    "    else:\n",
    "        # Use first 10 numerical columns\n",
    "        key_vars = numerical_cols[:10]\n",
    "\n",
    "print(f\"\\nBasic statistics for key variables:\")\n",
    "print(df[key_vars].describe().round(2))\n",
    "\n",
    "# 4. Target variable analysis (assuming 'price' is the target)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TARGET VARIABLE ANALYSIS (PRICE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find price column\n",
    "price_col = 'price' if 'price' in df.columns else None\n",
    "if not price_col:\n",
    "    for col in df.columns:\n",
    "        if 'price' in col.lower():\n",
    "            price_col = col\n",
    "            break\n",
    "\n",
    "if price_col:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Original distribution\n",
    "    axes[0].hist(df[price_col], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title(f'{price_col} Distribution')\n",
    "    axes[0].set_xlabel(price_col)\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].axvline(df[price_col].mean(), color='red', linestyle='--', label=f'Mean: ${df[price_col].mean():,.0f}')\n",
    "    axes[0].axvline(df[price_col].median(), color='green', linestyle='--', label=f'Median: ${df[price_col].median():,.0f}')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Boxplot\n",
    "    axes[1].boxplot(df[price_col])\n",
    "    axes[1].set_title(f'{price_col} Boxplot')\n",
    "    axes[1].set_ylabel(price_col)\n",
    "    \n",
    "    # Log transformation (if no negative/zero prices)\n",
    "    if (df[price_col] > 0).all():\n",
    "        axes[2].hist(np.log1p(df[price_col]), bins=50, edgecolor='black', alpha=0.7)\n",
    "        axes[2].set_title(f'Log-Transformed {price_col}')\n",
    "        axes[2].set_xlabel(f'log({price_col})')\n",
    "        axes[2].set_ylabel('Frequency')\n",
    "    else:\n",
    "        # If negative values exist, show cumulative distribution\n",
    "        axes[2].hist(df[price_col], bins=50, cumulative=True, edgecolor='black', alpha=0.7)\n",
    "        axes[2].set_title(f'Cumulative {price_col} Distribution')\n",
    "        axes[2].set_xlabel(price_col)\n",
    "        axes[2].set_ylabel('Cumulative Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Price statistics\n",
    "    print(f\"\\n{price_col} Statistics:\")\n",
    "    print(f\"  Mean: ${df[price_col].mean():,.2f}\")\n",
    "    print(f\"  Median: ${df[price_col].median():,.2f}\")\n",
    "    print(f\"  Std Dev: ${df[price_col].std():,.2f}\")\n",
    "    print(f\"  Min: ${df[price_col].min():,.2f}\")\n",
    "    print(f\"  Max: ${df[price_col].max():,.2f}\")\n",
    "    print(f\"  Skewness: {df[price_col].skew():.2f}\")\n",
    "    print(f\"  Kurtosis: {df[price_col].kurtosis():.2f}\")\n",
    "else:\n",
    "    print(\"Warning: Could not find price column in dataset\")\n",
    "    print(f\"Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "# 5. Correlation analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if price_col and len(numerical_cols) > 1:\n",
    "    # Calculate correlation\n",
    "    corr_matrix = df[numerical_cols].corr()\n",
    "    \n",
    "    # Get correlation with price\n",
    "    if price_col in corr_matrix.columns:\n",
    "        price_corr = corr_matrix[price_col].sort_values(ascending=False)\n",
    "        print(\"\\nTop 10 correlations with price:\")\n",
    "        print(price_corr.head(10))\n",
    "        \n",
    "        # Visualize correlation heatmap\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_corr_features = price_corr.index[:10].tolist()\n",
    "        top_corr_matrix = df[top_corr_features].corr()\n",
    "        \n",
    "        sns.heatmap(top_corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                    center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "        plt.title('Top 10 Features Correlation with Price', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Price column '{price_col}' not found in numerical columns\")\n",
    "else:\n",
    "    print(\"Not enough numerical columns for correlation analysis\")\n",
    "\n",
    "# 6. High-value properties analysis (≥ $650K)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HIGH-VALUE PROPERTIES ANALYSIS (≥ $650K)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if price_col:\n",
    "    df['high_value'] = df[price_col] >= 650000\n",
    "    high_value = df[df['high_value']]\n",
    "    regular_value = df[~df['high_value']]\n",
    "    \n",
    "    print(f\"High-value properties (≥ $650K): {len(high_value):,}\")\n",
    "    print(f\"Regular properties (< $650K): {len(regular_value):,}\")\n",
    "    print(f\"Percentage high-value: {len(high_value)/len(df)*100:.1f}%\")\n",
    "    \n",
    "    print(\"\\nComparison - High Value vs Regular Properties:\")\n",
    "    \n",
    "    # Define comparison columns based on available data\n",
    "    possible_comp_cols = ['grade', 'sqft_living', 'bathrooms', 'bedrooms', \n",
    "                         'waterfront', 'view', 'condition', 'sqft_above',\n",
    "                         'sqft_lot', 'floors', 'yr_built']\n",
    "    \n",
    "    comp_cols = [col for col in possible_comp_cols if col in df.columns]\n",
    "    \n",
    "    if comp_cols:\n",
    "        comparison_data = []\n",
    "        for col in comp_cols:\n",
    "            hv_mean = high_value[col].mean() if len(high_value) > 0 else 0\n",
    "            rv_mean = regular_value[col].mean() if len(regular_value) > 0 else 0\n",
    "            \n",
    "            if rv_mean != 0:  # Avoid division by zero\n",
    "                pct_diff = ((hv_mean - rv_mean) / rv_mean) * 100\n",
    "            else:\n",
    "                pct_diff = 0\n",
    "                \n",
    "            comparison_data.append({\n",
    "                'Feature': col,\n",
    "                'High_Value_Mean': hv_mean,\n",
    "                'Regular_Mean': rv_mean,\n",
    "                'Difference': hv_mean - rv_mean,\n",
    "                'Pct_Difference (%)': pct_diff\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        print(comparison_df.to_string(index=False))\n",
    "        \n",
    "        # Visualize top differences\n",
    "        top_diff = comparison_df.nlargest(5, 'Pct_Difference (%)')\n",
    "        if len(top_diff) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            y_pos = np.arange(len(top_diff))\n",
    "            ax.barh(y_pos, top_diff['Pct_Difference (%)'])\n",
    "            ax.set_yticks(y_pos)\n",
    "            ax.set_yticklabels(top_diff['Feature'])\n",
    "            ax.set_xlabel('Percentage Difference (%)')\n",
    "            ax.set_title('Top Features Differentiating High-Value Properties')\n",
    "            ax.invert_yaxis()  # Highest on top\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No comparison columns found in dataset\")\n",
    "else:\n",
    "    print(f\"Cannot analyze high-value properties: Price column not found\")\n",
    "\n",
    "# =========== PART 2: MODELING (Based on EDA insights) ===========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODELING PHASE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if price_col and len(numerical_cols) > 2:\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.linear_model import LinearRegression, Ridge\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "    \n",
    "    # Select features based on correlation analysis\n",
    "    if 'price_corr' in locals() and len(price_corr) > 1:\n",
    "        # Use top 10 features excluding price itself\n",
    "        top_features = price_corr.index[1:11].tolist() if len(price_corr) > 10 else price_corr.index[1:].tolist()\n",
    "    else:\n",
    "        # Fallback: use all numerical columns except price and ID\n",
    "        top_features = [col for col in numerical_cols if col != price_col and 'id' not in col.lower()]\n",
    "        top_features = top_features[:10]  # Take first 10\n",
    "    \n",
    "    print(f\"\\nSelected features for modeling ({len(top_features)}):\")\n",
    "    print(top_features)\n",
    "    \n",
    "    X = df[top_features]\n",
    "    y = df[price_col]\n",
    "    \n",
    "    # Handle any missing values\n",
    "    if X.isnull().sum().sum() > 0:\n",
    "        print(f\"\\nFilling {X.isnull().sum().sum()} missing values with median...\")\n",
    "        X = X.fillna(X.median())\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train multiple models\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(alpha=1.0),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "        'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=5)\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, \n",
    "                                    cv=5, scoring='r2', n_jobs=-1)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'RMSE': f\"${rmse:,.0f}\",\n",
    "            'MAE': f\"${mae:,.0f}\",\n",
    "            'R²': f\"{r2:.3f}\",\n",
    "            'CV R² Mean': f\"{cv_scores.mean():.3f}\",\n",
    "            'CV R² Std': f\"{cv_scores.std():.3f}\"\n",
    "        })\n",
    "        \n",
    "        print(f\"  R²: {r2:.3f}\")\n",
    "        print(f\"  RMSE: ${rmse:,.0f}\")\n",
    "        print(f\"  MAE: ${mae:,.0f}\")\n",
    "        print(f\"  CV R²: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
    "    \n",
    "    # Display results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print(\"=\"*60)\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Feature importance from Random Forest\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FEATURE IMPORTANCE (Random Forest)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': top_features,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(feature_importance.to_string(index=False))\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Feature Importance - Random Forest')\n",
    "    plt.gca().invert_yaxis()  # Highest importance on top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =========== PART 3: BUSINESS INSIGHTS ===========\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"KEY BUSINESS INSIGHTS FOR MANAGEMENT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if 'high_value' in df.columns:\n",
    "        print(\"\\n1. HIGH-VALUE PROPERTIES (≥ $650K):\")\n",
    "        print(f\"   • Represent {len(high_value)/len(df)*100:.1f}% of all properties\")\n",
    "        print(f\"   • Average price: ${high_value[price_col].mean():,.0f}\")\n",
    "        print(f\"   • Key differentiators:\")\n",
    "        \n",
    "        # Show top 3 differentiating features\n",
    "        if 'comparison_df' in locals():\n",
    "            top_diff_features = comparison_df.nlargest(3, 'Pct_Difference (%)')\n",
    "            for _, row in top_diff_features.iterrows():\n",
    "                print(f\"     - {row['Feature']}: {row['High_Value_Mean']:.1f} vs {row['Regular_Mean']:.1f} ({row['Pct_Difference (%)']:+.1f}%)\")\n",
    "    \n",
    "    print(\"\\n2. PREDICTIVE MODELING RESULTS:\")\n",
    "    best_model_row = results_df.loc[results_df['R²'].astype(float).idxmax()]\n",
    "    print(f\"   • Best performing model: {best_model_row['Model']}\")\n",
    "    print(f\"   • R² Score: {best_model_row['R²']}\")\n",
    "    print(f\"   • Average prediction error: {best_model_row['MAE']}\")\n",
    "    \n",
    "    print(\"\\n3. TOP PRICE PREDICTORS:\")\n",
    "    for i, row in feature_importance.head(3).iterrows():\n",
    "        print(f\"   • {row['Feature']} (importance: {row['Importance']:.3f})\")\n",
    "    \n",
    "    print(\"\\n4. RECOMMENDATIONS:\")\n",
    "    print(\"   • Focus on improving top predictors (see above) for property value appreciation\")\n",
    "    print(\"   • High-value properties show distinct characteristics - target these features\")\n",
    "    print(\"   • Use the Random Forest model for accurate price predictions\")\n",
    "    print(\"   • Monitor waterfront and grade as key value drivers\")\n",
    "    \n",
    "    # Prepare for Tableau (optional)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TABLEAU PREPARATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    tableau_df = df.copy()\n",
    "    \n",
    "    # Create useful derived columns for Tableau\n",
    "    if price_col:\n",
    "        tableau_df['price_category'] = np.where(tableau_df[price_col] >= 650000, \n",
    "                                               'High (≥$650K)', 'Regular (<$650K)')\n",
    "        \n",
    "        # Create price per sqft if sqft_living exists\n",
    "        if 'sqft_living' in tableau_df.columns:\n",
    "            tableau_df['price_per_sqft'] = tableau_df[price_col] / tableau_df['sqft_living']\n",
    "            print(\"   • Created 'price_per_sqft' column\")\n",
    "        \n",
    "        print(\"   • Created 'price_category' column\")\n",
    "    \n",
    "    # Save for Tableau\n",
    "    tableau_df.to_csv('../data/house_data_tableau_ready.csv', index=False)\n",
    "    print(f\"   • Tableau-ready data saved to: ../data/house_data_tableau_ready.csv\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping modeling phase - insufficient data or price column not found\")\n",
    "    print(f\"Price column found: {price_col}\")\n",
    "    print(f\"Numerical columns: {len(numerical_cols)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33faf300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET EXPLORATION\n",
      "============================================================\n",
      "Dataset shape: (21596, 21)\n",
      "Columns (21):\n",
      "  1. 7129300520           - int64\n",
      "  2. 10/13/14             - object\n",
      "  3. 3                    - int64\n",
      "  4. 1                    - float64\n",
      "  5. 1180                 - int64\n",
      "  6. 5650                 - int64\n",
      "  7. 1.1                  - float64\n",
      "  8. 0                    - int64\n",
      "  9. 0.1                  - int64\n",
      " 10. 3.1                  - int64\n",
      " 11. 7                    - int64\n",
      " 12. 1180.1               - int64\n",
      " 13. 0.2                  - int64\n",
      " 14. 1955                 - int64\n",
      " 15. 0.3                  - int64\n",
      " 16. 98178                - int64\n",
      " 17. 47.5112              - float64\n",
      " 18. -122.257             - float64\n",
      " 19. 1340                 - int64\n",
      " 20. 5650.1               - int64\n",
      " 21. 221900               - int64\n",
      "\n",
      "============================================================\n",
      "LOOKING FOR PRICE-RELATED COLUMNS\n",
      "============================================================\n",
      "No obvious price columns found. Showing first 5 rows:\n",
      "   7129300520 10/13/14  3     1  1180    5650  1.1  0  0.1  3.1  ...  1180.1  \\\n",
      "0  6414100192  12/9/14  3  2.25  2570    7242  2.0  0    0    3  ...    2170   \n",
      "1  5631500400  2/25/15  2  1.00   770   10000  1.0  0    0    3  ...     770   \n",
      "2  2487200875  12/9/14  4  3.00  1960    5000  1.0  0    0    5  ...    1050   \n",
      "3  1954400510  2/18/15  3  2.00  1680    8080  1.0  0    0    3  ...    1680   \n",
      "4  7237550310  5/12/14  4  4.50  5420  101930  1.0  0    0    3  ...    3890   \n",
      "\n",
      "    0.2  1955   0.3  98178  47.5112  -122.257  1340  5650.1   221900  \n",
      "0   400  1951  1991  98125  47.7210  -122.319  1690    7639   538000  \n",
      "1     0  1933     0  98028  47.7379  -122.233  2720    8062   180000  \n",
      "2   910  1965     0  98136  47.5208  -122.393  1360    5000   604000  \n",
      "3     0  1987     0  98074  47.6168  -122.045  1800    7503   510000  \n",
      "4  1530  2001     0  98053  47.6561  -122.005  4760  101930  1230000  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "============================================================\n",
      "COLUMNS AVAILABLE\n",
      "============================================================\n",
      "All columns in your dataset:\n",
      "- '7129300520'\n",
      "- '10/13/14'\n",
      "- '3'\n",
      "- '1'\n",
      "- '1180'\n",
      "- '5650'\n",
      "- '1.1'\n",
      "- '0'\n",
      "- '0.1'\n",
      "- '3.1'\n",
      "- '7'\n",
      "- '1180.1'\n",
      "- '0.2'\n",
      "- '1955'\n",
      "- '0.3'\n",
      "- '98178'\n",
      "- '47.5112'\n",
      "- '-122.257'\n",
      "- '1340'\n",
      "- '5650.1'\n",
      "- '221900'\n"
     ]
    }
   ],
   "source": [
    "# === STEP 1: EXPLORE YOUR DATASET STRUCTURE ===\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data/regression_data.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET EXPLORATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns ({len(df.columns)}):\")\n",
    "\n",
    "# Display all columns with their data types\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:3}. {col:20} - {df[col].dtype}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOOKING FOR PRICE-RELATED COLUMNS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Look for columns that might contain price information\n",
    "price_keywords = ['price', 'Price', 'PRICE', 'value', 'Value', 'VALUE', \n",
    "                  'selling', 'Selling', 'sale', 'Sale', 'cost', 'Cost']\n",
    "\n",
    "price_columns = []\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    for keyword in price_keywords:\n",
    "        if keyword.lower() in col_lower:\n",
    "            price_columns.append(col)\n",
    "            break\n",
    "\n",
    "if price_columns:\n",
    "    print(f\"Found potential price columns: {price_columns}\")\n",
    "    for col in price_columns:\n",
    "        print(f\"\\nStatistics for '{col}':\")\n",
    "        print(df[col].describe())\n",
    "else:\n",
    "    print(\"No obvious price columns found. Showing first 5 rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLUMNS AVAILABLE\")\n",
    "print(\"=\"*60)\n",
    "print(\"All columns in your dataset:\")\n",
    "for col in df.columns:\n",
    "    print(f\"- '{col}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f822360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Warning: Using '221900' as target variable\n",
      "Target column identified: '221900'\n",
      "\n",
      "============================================================\n",
      "IDENTIFYING KEY FEATURES\n",
      "============================================================\n",
      "✗ sqft_living: Not found\n",
      "✗ sqft_lot: Not found\n",
      "✗ bedrooms: Not found\n",
      "✗ bathrooms: Not found\n",
      "✗ grade: Not found\n",
      "✗ waterfront: Not found\n",
      "✗ condition: Not found\n",
      "✗ view: Not found\n",
      "✗ floors: Not found\n",
      "✗ yr_built: Not found\n",
      "✗ sqft_above: Not found\n",
      "✗ sqft_basement: Not found\n",
      "✗ sqft_living15: Not found\n",
      "✗ sqft_lot15: Not found\n",
      "\n",
      "Using '221900' for price analysis...\n",
      "Price statistics:\n",
      "  Min: $78,000\n",
      "  Max: $7,700,000\n",
      "  Median: $450,000\n",
      "Created price categories: ['< $300K', '$300K-500K', '$500K-650K', '$650K-1M', '> $1M']\n",
      "Created 'is_high_value' flag (≥ $650K)\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "✓ Tableau-ready dataset saved to: data/house_data_tableau_ready.csv\n",
      "  Original shape: (21596, 21)\n",
      "  New shape: (21596, 23)\n",
      "  Price column used: '221900'\n",
      "\n",
      "New columns created (2):\n",
      "  - price_category\n",
      "  - is_high_value\n",
      "\n",
      "Sample of prepared data (first 3 rows):\n",
      "  price_category  is_high_value\n",
      "0     $500K-650K          False\n",
      "1        < $300K          False\n",
      "2     $500K-650K          False\n",
      "\n",
      "============================================================\n",
      "NEXT STEPS FOR TABLEAU\n",
      "============================================================\n",
      "1. Open Tableau Desktop\n",
      "2. Connect to: data/house_data_tableau_ready.csv\n",
      "3. Use '221900' as your target variable\n",
      "4. Use the created categories (price_category, size_category, etc.) for filtering\n",
      "5. Create dashboards as per the previous instructions\n"
     ]
    }
   ],
   "source": [
    "# === FLEXIBLE TABLEAU DATA PREPARATION ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('data/regression_data.csv')\n",
    "\n",
    "# Identify the target price column\n",
    "def find_price_column(df):\n",
    "    \"\"\"Find the price/target column in the dataset\"\"\"\n",
    "    price_keywords = ['price', 'Price', 'PRICE', 'value', 'Value', 'target', \n",
    "                     'Target', 'y', 'Y', 'selling', 'sale', 'cost']\n",
    "    \n",
    "    # First, check for exact matches\n",
    "    for col in df.columns:\n",
    "        if col.lower() in ['price', 'target', 'y']:\n",
    "            return col\n",
    "    \n",
    "    # Check for partial matches\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        for keyword in price_keywords:\n",
    "            if keyword in col_lower:\n",
    "                return col\n",
    "    \n",
    "    # If no price column found, use the last numerical column\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        print(f\"⚠ Warning: Using '{numerical_cols[-1]}' as target variable\")\n",
    "        return numerical_cols[-1]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Find the price column\n",
    "price_col = find_price_column(df)\n",
    "print(f\"Target column identified: '{price_col}'\")\n",
    "\n",
    "# Let's see what other key columns we have\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IDENTIFYING KEY FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Common feature names in house price datasets\n",
    "feature_mapping = {\n",
    "    'sqft_living': ['sqft_living', 'living_area', 'area_living', 'sqftliving'],\n",
    "    'sqft_lot': ['sqft_lot', 'lot_area', 'area_lot', 'sqftlot'],\n",
    "    'bedrooms': ['bedrooms', 'bedroom', 'beds', 'bed'],\n",
    "    'bathrooms': ['bathrooms', 'bathroom', 'baths', 'bath'],\n",
    "    'grade': ['grade', 'Grade', 'GRADE', 'overall_grade'],\n",
    "    'waterfront': ['waterfront', 'Waterfront', 'WATERFRONT', 'view_water'],\n",
    "    'condition': ['condition', 'Condition', 'CONDITION', 'overall_cond'],\n",
    "    'view': ['view', 'View', 'VIEW'],\n",
    "    'floors': ['floors', 'Floors', 'FLOORS', 'stories'],\n",
    "    'yr_built': ['yr_built', 'year_built', 'built_year', 'yearbuilt'],\n",
    "    'sqft_above': ['sqft_above', 'above_area', 'area_above'],\n",
    "    'sqft_basement': ['sqft_basement', 'basement_area', 'area_basement'],\n",
    "    'sqft_living15': ['sqft_living15', 'living_area_2015'],\n",
    "    'sqft_lot15': ['sqft_lot15', 'lot_area_2015']\n",
    "}\n",
    "\n",
    "# Map actual column names to standard names\n",
    "standard_cols = {}\n",
    "for standard_name, possible_names in feature_mapping.items():\n",
    "    found = False\n",
    "    for possible in possible_names:\n",
    "        if possible in df.columns:\n",
    "            standard_cols[standard_name] = possible\n",
    "            found = True\n",
    "            print(f\"✓ {standard_name}: '{possible}'\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"✗ {standard_name}: Not found\")\n",
    "\n",
    "# Create Tableau-optimized dataset\n",
    "tableau_df = df.copy()\n",
    "\n",
    "# Rename columns to standard names for easier reference\n",
    "for std_name, actual_name in standard_cols.items():\n",
    "    if std_name != actual_name:\n",
    "        tableau_df[std_name] = tableau_df[actual_name]\n",
    "\n",
    "# 1. Create price categories - USING THE IDENTIFIED PRICE COLUMN\n",
    "print(f\"\\nUsing '{price_col}' for price analysis...\")\n",
    "\n",
    "# Check price distribution to set appropriate bins\n",
    "if price_col:\n",
    "    price_stats = tableau_df[price_col].describe()\n",
    "    min_price = price_stats['min']\n",
    "    max_price = price_stats['max']\n",
    "    median_price = price_stats['50%']\n",
    "    \n",
    "    print(f\"Price statistics:\")\n",
    "    print(f\"  Min: ${min_price:,.0f}\")\n",
    "    print(f\"  Max: ${max_price:,.0f}\")\n",
    "    print(f\"  Median: ${median_price:,.0f}\")\n",
    "    \n",
    "    # Create dynamic bins based on data\n",
    "    if max_price <= 1000000:\n",
    "        bins = [0, 300000, 500000, 650000, max_price]\n",
    "        labels = ['< $300K', '$300K-500K', '$500K-650K', f'$650K-${max_price/1000:.0f}K']\n",
    "    else:\n",
    "        bins = [0, 300000, 500000, 650000, 1000000, max_price]\n",
    "        labels = ['< $300K', '$300K-500K', '$500K-650K', '$650K-1M', f'> $1M']\n",
    "    \n",
    "    tableau_df['price_category'] = pd.cut(tableau_df[price_col], bins=bins, labels=labels)\n",
    "    print(f\"Created price categories: {labels}\")\n",
    "\n",
    "# 2. Create size categories if sqft_living exists\n",
    "if 'sqft_living' in tableau_df.columns:\n",
    "    # Get living area statistics\n",
    "    living_stats = tableau_df['sqft_living'].describe()\n",
    "    \n",
    "    # Create dynamic bins\n",
    "    max_living = living_stats['max']\n",
    "    if max_living <= 5000:\n",
    "        bins = [0, 1000, 2000, 3000, max_living]\n",
    "        labels = ['<1K sqft', '1K-2K sqft', '2K-3K sqft', f'3K-{max_living/1000:.0f}K sqft']\n",
    "    else:\n",
    "        bins = [0, 1000, 2000, 3000, 4000, max_living]\n",
    "        labels = ['<1K sqft', '1K-2K sqft', '2K-3K sqft', '3K-4K sqft', f'>4K sqft']\n",
    "    \n",
    "    tableau_df['size_category'] = pd.cut(tableau_df['sqft_living'], bins=bins, labels=labels)\n",
    "    print(f\"Created size categories: {labels}\")\n",
    "\n",
    "# 3. Create house age if yr_built exists\n",
    "if 'yr_built' in tableau_df.columns:\n",
    "    tableau_df['house_age'] = 2015 - tableau_df['yr_built']  # Using 2015 as reference\n",
    "    \n",
    "    # Create age categories\n",
    "    age_bins = [0, 5, 10, 20, 30, 50, 100, float('inf')]\n",
    "    age_labels = ['<5 yrs', '5-10 yrs', '10-20 yrs', '20-30 yrs', '30-50 yrs', '50-100 yrs', '>100 yrs']\n",
    "    tableau_df['age_category'] = pd.cut(tableau_df['house_age'], bins=age_bins, labels=age_labels)\n",
    "    print(f\"Created age categories\")\n",
    "\n",
    "# 4. Calculate price per square foot if both price and sqft_living exist\n",
    "if price_col and 'sqft_living' in tableau_df.columns:\n",
    "    tableau_df['price_per_sqft'] = tableau_df[price_col] / tableau_df['sqft_living']\n",
    "    print(f\"Created 'price_per_sqft' column\")\n",
    "\n",
    "# 5. Create boolean flags\n",
    "if 'waterfront' in tableau_df.columns:\n",
    "    tableau_df['is_waterfront'] = tableau_df['waterfront'] == 1\n",
    "    print(f\"Created 'is_waterfront' flag\")\n",
    "\n",
    "if 'yr_renovated' in tableau_df.columns:\n",
    "    tableau_df['is_renovated'] = tableau_df['yr_renovated'] > 0\n",
    "    print(f\"Created 'is_renovated' flag\")\n",
    "\n",
    "if 'grade' in tableau_df.columns:\n",
    "    tableau_df['high_grade'] = tableau_df['grade'] >= 10\n",
    "    print(f\"Created 'high_grade' flag\")\n",
    "\n",
    "if price_col:\n",
    "    tableau_df['is_high_value'] = tableau_df[price_col] >= 650000\n",
    "    print(f\"Created 'is_high_value' flag (≥ $650K)\")\n",
    "\n",
    "# 6. Extract date components if date column exists\n",
    "date_columns = [col for col in tableau_df.columns if 'date' in col.lower()]\n",
    "if date_columns:\n",
    "    date_col = date_columns[0]\n",
    "    try:\n",
    "        tableau_df[date_col] = pd.to_datetime(tableau_df[date_col])\n",
    "        tableau_df['year'] = tableau_df[date_col].dt.year\n",
    "        tableau_df['month'] = tableau_df[date_col].dt.month\n",
    "        tableau_df['month_name'] = tableau_df[date_col].dt.month_name()\n",
    "        \n",
    "        # Create season\n",
    "        def get_season(month):\n",
    "            if month in [12, 1, 2]:\n",
    "                return 'Winter'\n",
    "            elif month in [3, 4, 5]:\n",
    "                return 'Spring'\n",
    "            elif month in [6, 7, 8]:\n",
    "                return 'Summer'\n",
    "            else:\n",
    "                return 'Fall'\n",
    "        \n",
    "        tableau_df['season'] = tableau_df['month'].apply(get_season)\n",
    "        print(f\"Created date-based columns from '{date_col}'\")\n",
    "    except:\n",
    "        print(f\"Could not parse date column '{date_col}'\")\n",
    "\n",
    "# 7. Create view quality categories\n",
    "if 'view' in tableau_df.columns:\n",
    "    # Check view value range\n",
    "    view_values = tableau_df['view'].unique()\n",
    "    if len(view_values) <= 6:\n",
    "        # Create categorical mapping\n",
    "        view_labels = {0: 'No View', 1: 'Fair View', 2: 'Average View', \n",
    "                      3: 'Good View', 4: 'Excellent View'}\n",
    "        tableau_df['view_category'] = tableau_df['view'].map(view_labels)\n",
    "        print(f\"Created 'view_category'\")\n",
    "\n",
    "# 8. Create condition categories\n",
    "if 'condition' in tableau_df.columns:\n",
    "    condition_values = tableau_df['condition'].unique()\n",
    "    if len(condition_values) <= 5:\n",
    "        condition_labels = {1: 'Poor', 2: 'Below Avg', 3: 'Average', \n",
    "                          4: 'Good', 5: 'Excellent'}\n",
    "        tableau_df['condition_category'] = tableau_df['condition'].map(condition_labels)\n",
    "        print(f\"Created 'condition_category'\")\n",
    "\n",
    "# 9. Calculate bedroom-to-bathroom ratio if both exist\n",
    "if 'bedrooms' in tableau_df.columns and 'bathrooms' in tableau_df.columns:\n",
    "    tableau_df['bed_bath_ratio'] = tableau_df['bedrooms'] / tableau_df['bathrooms'].replace(0, np.nan)\n",
    "    print(f\"Created 'bed_bath_ratio'\")\n",
    "\n",
    "# 10. Create location segments if coordinates exist\n",
    "if 'lat' in tableau_df.columns and 'long' in tableau_df.columns:\n",
    "    if tableau_df['lat'].notna().any() and tableau_df['long'].notna().any():\n",
    "        # Create simple location categories\n",
    "        lat_median = tableau_df['lat'].median()\n",
    "        long_median = tableau_df['long'].median()\n",
    "        \n",
    "        tableau_df['location_quadrant'] = np.where(\n",
    "            (tableau_df['lat'] >= lat_median) & (tableau_df['long'] >= long_median),\n",
    "            'NE',\n",
    "            np.where(\n",
    "                (tableau_df['lat'] >= lat_median) & (tableau_df['long'] < long_median),\n",
    "                'NW',\n",
    "                np.where(\n",
    "                    (tableau_df['lat'] < lat_median) & (tableau_df['long'] >= long_median),\n",
    "                    'SE',\n",
    "                    'SW'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        print(f\"Created 'location_quadrant'\")\n",
    "\n",
    "# Save for Tableau\n",
    "output_file = 'data/house_data_tableau_ready.csv'\n",
    "tableau_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Tableau-ready dataset saved to: {output_file}\")\n",
    "print(f\"  Original shape: {df.shape}\")\n",
    "print(f\"  New shape: {tableau_df.shape}\")\n",
    "print(f\"  Price column used: '{price_col}'\")\n",
    "\n",
    "# Show new columns created\n",
    "new_columns = [col for col in tableau_df.columns if col not in df.columns]\n",
    "print(f\"\\nNew columns created ({len(new_columns)}):\")\n",
    "for col in new_columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Show sample of prepared data\n",
    "print(f\"\\nSample of prepared data (first 3 rows):\")\n",
    "print(tableau_df[new_columns[:5]].head(3) if new_columns else tableau_df.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS FOR TABLEAU\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Open Tableau Desktop\")\n",
    "print(\"2. Connect to: data/house_data_tableau_ready.csv\")\n",
    "print(f\"3. Use '{price_col}' as your target variable\")\n",
    "print(\"4. Use the created categories (price_category, size_category, etc.) for filtering\")\n",
    "print(\"5. Create dashboards as per the previous instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1678d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row appears to contain data, not column names\n",
      "Trying to load with proper column names...\n",
      "Assigned column names: ['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
      "\n",
      "============================================================\n",
      "DATASET STRUCTURE\n",
      "============================================================\n",
      "Shape: (21597, 21)\n",
      "Columns: ['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
      "\n",
      "First 3 rows:\n",
      "           id      date  price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
      "0  7129300520  10/13/14      3      1.00       1180         5650       1.0   \n",
      "1  6414100192   12/9/14      3      2.25       2570         7242       2.0   \n",
      "2  5631500400   2/25/15      2      1.00        770        10000       1.0   \n",
      "\n",
      "   floors  waterfront  view  ...  grade  sqft_above  sqft_basement  yr_built  \\\n",
      "0       0           0     3  ...   1180           0           1955         0   \n",
      "1       0           0     3  ...   2170         400           1951      1991   \n",
      "2       0           0     3  ...    770           0           1933         0   \n",
      "\n",
      "   yr_renovated  zipcode      lat  long  sqft_living15  sqft_lot15  \n",
      "0         98178  47.5112 -122.257  1340           5650      221900  \n",
      "1         98125  47.7210 -122.319  1690           7639      538000  \n",
      "2         98028  47.7379 -122.233  2720           8062      180000  \n",
      "\n",
      "[3 rows x 21 columns]\n",
      "\n",
      "Data types:\n",
      "id                 int64\n",
      "date              object\n",
      "price              int64\n",
      "bedrooms         float64\n",
      "bathrooms          int64\n",
      "sqft_living        int64\n",
      "sqft_lot         float64\n",
      "floors             int64\n",
      "waterfront         int64\n",
      "view               int64\n",
      "condition          int64\n",
      "grade              int64\n",
      "sqft_above         int64\n",
      "sqft_basement      int64\n",
      "yr_built           int64\n",
      "yr_renovated       int64\n",
      "zipcode          float64\n",
      "lat              float64\n",
      "long               int64\n",
      "sqft_living15      int64\n",
      "sqft_lot15         int64\n",
      "dtype: object\n",
      "\n",
      "============================================================\n",
      "FINDING PRICE COLUMN\n",
      "============================================================\n",
      "Potential price columns found:\n",
      "  'yr_renovated': median = $98,065, type = int64\n",
      "  'sqft_lot15': median = $450,000, type = int64\n",
      "\n",
      "Selected price column: 'sqft_lot15'\n",
      "\n",
      "============================================================\n",
      "PRICE STATISTICS\n",
      "============================================================\n",
      "Column: sqft_lot15\n",
      "Min: $78,000\n",
      "Max: $7,700,000\n",
      "Mean: $540,297\n",
      "Median: $450,000\n",
      "Missing values: 0\n",
      "\n",
      "Created price categories: ['< $300K', '$300K-500K', '$500K-650K', '$650K-1M', '> $1M']\n",
      "\n",
      "============================================================\n",
      "CREATING ADDITIONAL CATEGORIES\n",
      "============================================================\n",
      "Using 'sqft_living' for living area\n",
      "Created size categories\n",
      "Created price_per_sqft\n",
      "Created bed_bath_ratio\n",
      "Created high_grade based on 'grade'\n",
      "Created has_water_view based on 'waterfront'\n",
      "Created is_high_value flag\n",
      "Created date-based columns from 'date'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\profe\\AppData\\Local\\Temp\\ipykernel_34236\\1337167597.py:203: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  tableau_df[date_col] = pd.to_datetime(tableau_df[date_col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "✓ Tableau-ready dataset saved to: data/house_data_tableau_fixed.csv\n",
      "  Original shape: (21597, 21)\n",
      "  New shape: (21597, 31)\n",
      "  Price column: 'sqft_lot15'\n",
      "\n",
      "All columns in Tableau-ready dataset (31):\n",
      "  1. id\n",
      "  2. date\n",
      "  3. price\n",
      "  4. bedrooms\n",
      "  5. bathrooms\n",
      "  6. sqft_living\n",
      "  7. sqft_lot\n",
      "  8. floors\n",
      "  9. waterfront\n",
      " 10. view\n",
      " 11. condition\n",
      " 12. grade\n",
      " 13. sqft_above\n",
      " 14. sqft_basement\n",
      " 15. yr_built\n",
      " 16. yr_renovated\n",
      " 17. zipcode\n",
      " 18. lat\n",
      " 19. long\n",
      " 20. sqft_living15\n",
      " 21. sqft_lot15\n",
      " 22. price_category\n",
      " 23. size_category\n",
      " 24. price_per_sqft\n",
      " 25. bed_bath_ratio\n",
      " 26. high_grade\n",
      " 27. has_water_view\n",
      " 28. is_high_value\n",
      " 29. sale_year\n",
      " 30. sale_month\n",
      " 31. sale_quarter\n",
      "\n",
      "Sample data (first 2 rows):\n",
      "           id       date  price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
      "0  7129300520 2014-10-13      3      1.00       1180         5650       1.0   \n",
      "1  6414100192 2014-12-09      3      2.25       2570         7242       2.0   \n",
      "\n",
      "   floors  waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
      "0       0           0     3          7   1180           0           1955   \n",
      "1       0           0     3          7   2170         400           1951   \n",
      "\n",
      "   yr_built  yr_renovated  zipcode      lat  long  sqft_living15  sqft_lot15  \\\n",
      "0         0         98178  47.5112 -122.257  1340           5650      221900   \n",
      "1      1991         98125  47.7210 -122.319  1690           7639      538000   \n",
      "\n",
      "  price_category size_category  price_per_sqft  bed_bath_ratio  high_grade  \\\n",
      "0        < $300K      >4K sqft       39.274336        0.000847       False   \n",
      "1     $500K-650K      >4K sqft       74.288870        0.000875        True   \n",
      "\n",
      "   has_water_view  is_high_value  sale_year  sale_month  sale_quarter  \n",
      "0           False          False       2014          10             4  \n",
      "1           False          False       2014          12             4  \n",
      "\n",
      "============================================================\n",
      "TABLEAU PREPARATION GUIDE\n",
      "============================================================\n",
      "1. Open Tableau Desktop\n",
      "2. Connect to: data/house_data_tableau_fixed.csv\n",
      "3. Main variables to use:\n",
      "   - Target variable: 'sqft_lot15'\n",
      "   - Price categories: 'price_category'\n",
      "   - High-value filter: 'is_high_value'\n",
      "   - Size analysis: 'size_category'\n",
      "   - Efficiency metric: 'price_per_sqft'\n",
      "\n",
      "4. For high-value analysis (≥ $650K):\n",
      "   - Use 'is_high_value' as filter\n",
      "   - Compare with 'price_category'\n",
      "   - Analyze correlations with other features\n",
      "\n",
      "5. Dashboard creation steps:\n",
      "   a. Create KPI cards for counts and averages\n",
      "   b. Create distribution charts for price_category\n",
      "   c. Create comparison charts (high-value vs regular)\n",
      "   d. Add filters for interactive exploration\n",
      "   e. Create geographic map if lat/long columns exist\n"
     ]
    }
   ],
   "source": [
    "# === CORRECTED TABLEAU DATA PREPARATION ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data with proper header handling\n",
    "try:\n",
    "    # Try reading with header\n",
    "    df = pd.read_csv('data/regression_data.csv')\n",
    "    \n",
    "    # Check if first row looks like data (contains numbers)\n",
    "    first_row_numeric = pd.to_numeric(df.iloc[0], errors='coerce').notna().any()\n",
    "    \n",
    "    if first_row_numeric:\n",
    "        print(\"First row appears to contain data, not column names\")\n",
    "        print(\"Trying to load with proper column names...\")\n",
    "        \n",
    "        # Read without header and assign proper column names\n",
    "        df = pd.read_csv('data/regression_data.csv', header=None)\n",
    "        \n",
    "        # Based on common house price dataset columns\n",
    "        common_columns = [\n",
    "            'id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', \n",
    "            'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "            'lat', 'long', 'sqft_living15', 'sqft_lot15'\n",
    "        ]\n",
    "        \n",
    "        # Use appropriate number of columns\n",
    "        if len(df.columns) <= len(common_columns):\n",
    "            df.columns = common_columns[:len(df.columns)]\n",
    "        else:\n",
    "            # Use generic column names\n",
    "            df.columns = [f'col_{i}' for i in range(len(df.columns))]\n",
    "            \n",
    "        print(f\"Assigned column names: {list(df.columns)}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n",
    "    # Try alternative approach\n",
    "    try:\n",
    "        df = pd.read_csv('data/regression_data.csv', engine='python')\n",
    "    except:\n",
    "        df = pd.read_excel('data/regression_data.xls')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET STRUCTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Let's find the actual price column\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINDING PRICE COLUMN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Look for columns that could be price\n",
    "potential_price_cols = []\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        # Convert to numeric to check\n",
    "        numeric_col = pd.to_numeric(df[col], errors='coerce')\n",
    "        if numeric_col.notna().any():\n",
    "            # Check if values look like prices (typical range)\n",
    "            median_val = numeric_col.median()\n",
    "            if 50000 < median_val < 5000000:  # Reasonable price range\n",
    "                potential_price_cols.append((col, median_val, numeric_col.dtype))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "if potential_price_cols:\n",
    "    print(\"Potential price columns found:\")\n",
    "    for col, median_val, dtype in potential_price_cols:\n",
    "        print(f\"  '{col}': median = ${median_val:,.0f}, type = {dtype}\")\n",
    "    \n",
    "    # Select the most likely price column\n",
    "    # Prefer columns named 'price' or with highest median in reasonable range\n",
    "    price_col = None\n",
    "    for col, median_val, dtype in potential_price_cols:\n",
    "        if 'price' in str(col).lower():\n",
    "            price_col = col\n",
    "            break\n",
    "    \n",
    "    if not price_col:\n",
    "        # Choose column with median closest to typical house price\n",
    "        price_col = max(potential_price_cols, key=lambda x: x[1] if 100000 < x[1] < 2000000 else 0)[0]\n",
    "    \n",
    "    print(f\"\\nSelected price column: '{price_col}'\")\n",
    "else:\n",
    "    print(\"No obvious price column found. Using last numeric column.\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    price_col = numeric_cols[-1] if len(numeric_cols) > 0 else df.columns[-1]\n",
    "    print(f\"Using '{price_col}' as price column\")\n",
    "\n",
    "# Convert price column to numeric\n",
    "df[price_col] = pd.to_numeric(df[price_col], errors='coerce')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRICE STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Column: {price_col}\")\n",
    "print(f\"Min: ${df[price_col].min():,.0f}\")\n",
    "print(f\"Max: ${df[price_col].max():,.0f}\")\n",
    "print(f\"Mean: ${df[price_col].mean():,.0f}\")\n",
    "print(f\"Median: ${df[price_col].median():,.0f}\")\n",
    "print(f\"Missing values: {df[price_col].isna().sum()}\")\n",
    "\n",
    "# === CREATE TABLEAU-OPTIMIZED DATASET ===\n",
    "tableau_df = df.copy()\n",
    "\n",
    "# Standardize column names (remove any leading/trailing spaces)\n",
    "tableau_df.columns = [str(col).strip() for col in tableau_df.columns]\n",
    "price_col = price_col.strip()\n",
    "\n",
    "# 1. Create price categories\n",
    "price_data = tableau_df[price_col].dropna()\n",
    "if len(price_data) > 0:\n",
    "    min_price = price_data.min()\n",
    "    max_price = price_data.max()\n",
    "    \n",
    "    # Create dynamic bins\n",
    "    if max_price <= 1000000:\n",
    "        bins = [min_price-1, 300000, 500000, 650000, max_price]\n",
    "        labels = ['< $300K', '$300K-500K', '$500K-650K', f'≥ $650K']\n",
    "    else:\n",
    "        bins = [min_price-1, 300000, 500000, 650000, 1000000, max_price]\n",
    "        labels = ['< $300K', '$300K-500K', '$500K-650K', '$650K-1M', '> $1M']\n",
    "    \n",
    "    tableau_df['price_category'] = pd.cut(tableau_df[price_col], bins=bins, labels=labels, include_lowest=True)\n",
    "    print(f\"\\nCreated price categories: {labels}\")\n",
    "\n",
    "# 2. Identify and create other useful categories\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING ADDITIONAL CATEGORIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find living area column\n",
    "living_area_cols = [col for col in tableau_df.columns if any(term in str(col).lower() \n",
    "                    for term in ['sqft', 'area', 'living', 'size'])]\n",
    "if living_area_cols:\n",
    "    living_col = living_area_cols[0]\n",
    "    print(f\"Using '{living_col}' for living area\")\n",
    "    \n",
    "    # Create size categories\n",
    "    if pd.api.types.is_numeric_dtype(tableau_df[living_col]):\n",
    "        living_data = tableau_df[living_col].dropna()\n",
    "        if len(living_data) > 0:\n",
    "            bins = [0, 1000, 2000, 3000, 4000, float('inf')]\n",
    "            labels = ['<1K sqft', '1K-2K sqft', '2K-3K sqft', '3K-4K sqft', '>4K sqft']\n",
    "            tableau_df['size_category'] = pd.cut(tableau_df[living_col], bins=bins, labels=labels)\n",
    "            print(f\"Created size categories\")\n",
    "            \n",
    "            # Calculate price per sqft\n",
    "            tableau_df['price_per_sqft'] = tableau_df[price_col] / tableau_df[living_col]\n",
    "            print(f\"Created price_per_sqft\")\n",
    "\n",
    "# Find bedroom and bathroom columns\n",
    "bedroom_cols = [col for col in tableau_df.columns if any(term in str(col).lower() \n",
    "                for term in ['bed', 'room', 'brm'])]\n",
    "bathroom_cols = [col for col in tableau_df.columns if any(term in str(col).lower() \n",
    "                 for term in ['bath', 'bth'])]\n",
    "\n",
    "if bedroom_cols and bathroom_cols:\n",
    "    bedroom_col = bedroom_cols[0]\n",
    "    bathroom_col = bathroom_cols[0]\n",
    "    tableau_df['bed_bath_ratio'] = pd.to_numeric(tableau_df[bedroom_col], errors='coerce') / \\\n",
    "                                   pd.to_numeric(tableau_df[bathroom_col].replace(0, np.nan), errors='coerce')\n",
    "    print(f\"Created bed_bath_ratio\")\n",
    "\n",
    "# Find grade/condition columns\n",
    "for grade_term in ['grade', 'rating', 'score']:\n",
    "    grade_cols = [col for col in tableau_df.columns if grade_term in str(col).lower()]\n",
    "    if grade_cols:\n",
    "        grade_col = grade_cols[0]\n",
    "        if pd.api.types.is_numeric_dtype(tableau_df[grade_col]):\n",
    "            tableau_df['high_grade'] = tableau_df[grade_col] >= tableau_df[grade_col].median()\n",
    "            print(f\"Created high_grade based on '{grade_col}'\")\n",
    "        break\n",
    "\n",
    "# Find waterfront/view columns\n",
    "for waterfront_term in ['waterfront', 'water', 'view']:\n",
    "    waterfront_cols = [col for col in tableau_df.columns if waterfront_term in str(col).lower()]\n",
    "    if waterfront_cols:\n",
    "        waterfront_col = waterfront_cols[0]\n",
    "        if pd.api.types.is_numeric_dtype(tableau_df[waterfront_col]):\n",
    "            tableau_df['has_water_view'] = tableau_df[waterfront_col] > 0\n",
    "            print(f\"Created has_water_view based on '{waterfront_col}'\")\n",
    "        break\n",
    "\n",
    "# High value flag\n",
    "tableau_df['is_high_value'] = tableau_df[price_col] >= 650000\n",
    "print(f\"Created is_high_value flag\")\n",
    "\n",
    "# Find date column\n",
    "date_cols = [col for col in tableau_df.columns if any(term in str(col).lower() \n",
    "             for term in ['date', 'time', 'year', 'month'])]\n",
    "if date_cols:\n",
    "    date_col = date_cols[0]\n",
    "    try:\n",
    "        tableau_df[date_col] = pd.to_datetime(tableau_df[date_col], errors='coerce')\n",
    "        tableau_df['sale_year'] = tableau_df[date_col].dt.year\n",
    "        tableau_df['sale_month'] = tableau_df[date_col].dt.month\n",
    "        tableau_df['sale_quarter'] = tableau_df[date_col].dt.quarter\n",
    "        print(f\"Created date-based columns from '{date_col}'\")\n",
    "    except:\n",
    "        print(f\"Could not parse date column '{date_col}'\")\n",
    "\n",
    "# === SAVE FOR TABLEAU ===\n",
    "output_file = 'data/house_data_tableau_fixed.csv'\n",
    "tableau_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Tableau-ready dataset saved to: {output_file}\")\n",
    "print(f\"  Original shape: {df.shape}\")\n",
    "print(f\"  New shape: {tableau_df.shape}\")\n",
    "print(f\"  Price column: '{price_col}'\")\n",
    "\n",
    "# Show all columns\n",
    "print(f\"\\nAll columns in Tableau-ready dataset ({len(tableau_df.columns)}):\")\n",
    "for i, col in enumerate(tableau_df.columns, 1):\n",
    "    print(f\"{i:3}. {col}\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample data (first 2 rows):\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(tableau_df.head(2))\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TABLEAU PREPARATION GUIDE\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Open Tableau Desktop\")\n",
    "print(f\"2. Connect to: {output_file}\")\n",
    "print(f\"3. Main variables to use:\")\n",
    "print(f\"   - Target variable: '{price_col}'\")\n",
    "print(f\"   - Price categories: 'price_category'\")\n",
    "print(f\"   - High-value filter: 'is_high_value'\")\n",
    "if 'size_category' in tableau_df.columns:\n",
    "    print(f\"   - Size analysis: 'size_category'\")\n",
    "if 'price_per_sqft' in tableau_df.columns:\n",
    "    print(f\"   - Efficiency metric: 'price_per_sqft'\")\n",
    "\n",
    "print(\"\\n4. For high-value analysis (≥ $650K):\")\n",
    "print(\"   - Use 'is_high_value' as filter\")\n",
    "print(\"   - Compare with 'price_category'\")\n",
    "print(\"   - Analyze correlations with other features\")\n",
    "\n",
    "print(\"\\n5. Dashboard creation steps:\")\n",
    "print(\"   a. Create KPI cards for counts and averages\")\n",
    "print(\"   b. Create distribution charts for price_category\")\n",
    "print(\"   c. Create comparison charts (high-value vs regular)\")\n",
    "print(\"   d. Add filters for interactive exploration\")\n",
    "print(\"   e. Create geographic map if lat/long columns exist\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
